{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUg+3oQtV30fbAXva60qFL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyaxYordi/archivos-csv-o-excel/blob/main/M%C3%A9todo_descenso_del_gradiente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRo6I9g5xcjZ",
        "outputId": "c9f2299d-f787-4d51-a9b1-8e12581d0d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.333333333333333 -0.333333333333333]\n"
          ]
        }
      ],
      "source": [
        "# Librereias\n",
        "from sympy import *\n",
        "import numpy as np\n",
        "\n",
        "x = symbols(\"x\")\n",
        "y = symbols(\"y\")\n",
        "l = symbols(\"lambda\")\n",
        "\n",
        "# Funcion a optimizar\n",
        "f = x**2+x*y+y**2+x+y+1 # <------------------------\n",
        "\n",
        "\"\"\"\n",
        "  Valor de epsilon.\n",
        "  El programa se va a detener hasta que la norma\n",
        "  del gradiente sea menor o igual a epsilon.\n",
        "\"\"\"\n",
        "epsilon = 1e-15 # Valor de epsilon\n",
        "\n",
        "def grad(X):\n",
        "  return Matrix([diff(f,x).subs({x:X[0],y:X[1]}),\n",
        "                  diff(f,y).subs({x:X[0],y:X[1]})])\n",
        "\n",
        "class Descenso_del_gradiente:\n",
        "  x0 = Matrix([1,2])  # <------ Punto de partida\n",
        "  def loptimo(u):\n",
        "    v = u-l*grad(u)\n",
        "    p = f.subs({x:v[0],y:v[1]})\n",
        "    p = diff(p,l)\n",
        "    p = solve(p)\n",
        "    return p[0]\n",
        "  def i():\n",
        "    Descenso_del_gradiente.x0 = Descenso_del_gradiente.x0 - Descenso_del_gradiente.loptimo(Descenso_del_gradiente.x0)*grad(Descenso_del_gradiente.x0)\n",
        "    return Descenso_del_gradiente.x0\n",
        "\n",
        "for j in range(1000000):\n",
        "  Descenso_del_gradiente.i()\n",
        "  if grad(Descenso_del_gradiente.i()).norm()<=epsilon:\n",
        "    break\n",
        "\n",
        "# Se imprime el resultado\n",
        "X = np.array([Descenso_del_gradiente.i()[0].evalf(),Descenso_del_gradiente.i()[1].evalf()])\n",
        "print(X)"
      ]
    }
  ]
}